"""
Advanced IC Marking Preprocessing Module
Based on research papers for IC authentication and counterfeit detection

Key techniques from papers:
1. Harrison et al. - Automated Laser Marking Analysis for Counterfeit IC Identification
2. IC SynthLogo - Synthetic Logo Image Dataset for Counterfeit and Recycled IC detection
3. Deep Learning-based AOI System for Detecting Component Marks
4. Logo Classification and Data Augmentation Techniques for PCB Assurance

Implements:
- Multi-scale morphological operations
- Adaptive contrast enhancement for engraved text
- Specialized filters for laser-etched markings
- Noise reduction with edge preservation
- Multiple binarization strategies
- Text orientation correction
"""

import cv2
import numpy as np
from scipy import ndimage
from typing import List, Tuple, Dict


class ICMarkingPreprocessor:
    """
    Advanced preprocessing specifically designed for IC chip marking extraction
    Implements techniques from multiple research papers
    """
    
    def __init__(self):
        self.debug = False
    
    def preprocess_for_ocr(self, image: np.ndarray, method='ensemble') -> np.ndarray:
        """
        Main preprocessing pipeline - returns best preprocessed image
        
        Args:
            image: Input BGR image
            method: 'ensemble' returns best of multiple methods, 
                   or specify: 'laser', 'printed', 'embossed'
        """
        if method == 'ensemble':
            # Try multiple preprocessing strategies and return best
            variants = self.create_preprocessing_variants(image)
            # Return the first variant (usually the most aggressive)
            return variants[0][1] if variants else image
        elif method == 'laser':
            return self.preprocess_laser_etched(image)
        elif method == 'printed':
            return self.preprocess_printed_text(image)
        elif method == 'embossed':
            return self.preprocess_embossed_text(image)
        else:
            return self.preprocess_laser_etched(image)  # Default
    
    def create_preprocessing_variants(self, image: np.ndarray) -> List[Tuple[str, np.ndarray]]:
        """
        Create multiple preprocessing variants for ensemble methods
        Returns list of (variant_name, preprocessed_image) tuples
        """
        variants = []
        
        # Variant 1: Laser-etched optimized (most common for ICs)
        variants.append(('laser_etched', self.preprocess_laser_etched(image)))
        
        # Variant 2: High contrast printed text
        variants.append(('printed_text', self.preprocess_printed_text(image)))
        
        # Variant 3: Embossed/stamped text
        variants.append(('embossed_text', self.preprocess_embossed_text(image)))
        
        # Variant 4: Dark text on light background (inverted)
        variants.append(('inverted', self.preprocess_inverted_text(image)))
        
        return variants
    
    def preprocess_laser_etched(self, image: np.ndarray) -> np.ndarray:
        """
        Preprocessing optimized for laser-etched IC markings
        Based on Harrison et al. paper on automated laser marking analysis
        
        Laser-etched text characteristics:
        - Low contrast
        - Irregular edges
        - Often appears as slight indentations
        - May have oxidation or discoloration
        """
        # Convert to grayscale
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Step 1: Increase resolution if too small
        h, w = gray.shape
        if h < 400 or w < 400:
            scale = max(400 / h, 400 / w)
            gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
        
        # Step 2: Denoise while preserving edges (bilateral filter)
        denoised = cv2.bilateralFilter(gray, d=5, sigmaColor=50, sigmaSpace=50)
        
        # Step 3: Enhance local contrast using CLAHE with aggressive settings
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(4, 4))
        enhanced = clahe.apply(denoised)
        
        # Step 4: Detect edges to find text boundaries
        edges = cv2.Canny(enhanced, 30, 100)
        
        # Step 5: Dilate edges slightly to connect broken characters
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        edges_dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # Step 6: Use morphological gradient to enhance text
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        gradient = cv2.morphologyEx(enhanced, cv2.MORPH_GRADIENT, kernel)
        
        # Step 7: Combine gradient with enhanced image
        combined = cv2.addWeighted(enhanced, 0.7, gradient, 0.3, 0)
        
        # Step 8: Apply adaptive thresholding (Sauvola method simulation)
        # This works well for uneven illumination
        binary = self._adaptive_sauvola_threshold(combined, window_size=25, k=0.2)
        
        # Step 9: Morphological operations to clean up
        # Remove small noise
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
        
        # Close small gaps in characters
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel, iterations=1)
        
        return cleaned
    
    def preprocess_printed_text(self, image: np.ndarray) -> np.ndarray:
        """
        Preprocessing for printed/ink-based IC markings
        Optimized for high-contrast printed text
        """
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Increase size if needed
        h, w = gray.shape
        if h < 400 or w < 400:
            scale = max(400 / h, 400 / w)
            gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
        
        # Denoise
        denoised = cv2.fastNlMeansDenoising(gray, h=10)
        
        # Enhance contrast
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(denoised)
        
        # Sharpen the image
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        # Otsu's thresholding (works well for bimodal distributions)
        _, binary = cv2.threshold(sharpened, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Clean up
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return binary
    
    def preprocess_embossed_text(self, image: np.ndarray) -> np.ndarray:
        """
        Preprocessing for embossed/stamped IC markings
        Uses gradient-based enhancement to detect raised/indented text
        """
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # Resize if needed
        h, w = gray.shape
        if h < 400 or w < 400:
            scale = max(400 / h, 400 / w)
            gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)
        
        # Strong gaussian blur to remove texture
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Compute gradients in X and Y directions
        grad_x = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)
        
        # Compute gradient magnitude
        gradient = np.sqrt(grad_x**2 + grad_y**2)
        gradient = np.uint8(gradient / gradient.max() * 255)
        
        # Enhance the gradient
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gradient)
        
        # Threshold
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return binary
    
    def preprocess_inverted_text(self, image: np.ndarray) -> np.ndarray:
        """
        Preprocessing for dark text on light background
        Some IC markings appear inverted
        """
        # Use laser-etched preprocessing
        processed = self.preprocess_laser_etched(image)
        
        # Invert if the image is mostly white (dark text on light background)
        if np.mean(processed) > 127:
            processed = cv2.bitwise_not(processed)
        
        return processed
    
    def _adaptive_sauvola_threshold(self, image: np.ndarray, window_size: int = 25, 
                                   k: float = 0.2, r: float = 128) -> np.ndarray:
        """
        Sauvola thresholding - excellent for documents with varying illumination
        Based on: Sauvola, J., & PietikÃ¤inen, M. (2000)
        
        T(x,y) = m(x,y) * (1 + k * ((s(x,y) / r) - 1))
        where m is local mean, s is local standard deviation
        """
        # Ensure odd window size
        if window_size % 2 == 0:
            window_size += 1
        
        # Compute local mean
        mean = cv2.blur(image.astype(np.float32), (window_size, window_size))
        
        # Compute local standard deviation
        mean_sq = cv2.blur((image.astype(np.float32))**2, (window_size, window_size))
        std = np.sqrt(mean_sq - mean**2)
        
        # Compute Sauvola threshold
        threshold = mean * (1 + k * ((std / r) - 1))
        
        # Apply threshold
        binary = np.zeros_like(image)
        binary[image > threshold] = 255
        
        return binary.astype(np.uint8)
    
    def correct_skew(self, image: np.ndarray) -> np.ndarray:
        """
        Detect and correct text skew/rotation
        Important for improving OCR accuracy
        """
        # Find all non-zero points (text pixels)
        coords = np.column_stack(np.where(image > 0))
        
        if len(coords) < 10:
            return image
        
        # Fit a line to find angle
        angle = cv2.minAreaRect(coords)[-1]
        
        # Correct angle
        if angle < -45:
            angle = 90 + angle
        elif angle > 45:
            angle = angle - 90
        
        # Only correct if angle is significant
        if abs(angle) > 0.5:
            h, w = image.shape
            center = (w // 2, h // 2)
            M = cv2.getRotationMatrix2D(center, angle, 1.0)
            rotated = cv2.warpAffine(image, M, (w, h), 
                                    flags=cv2.INTER_CUBIC, 
                                    borderMode=cv2.BORDER_REPLICATE)
            return rotated
        
        return image
    
    def enhance_text_regions(self, image: np.ndarray) -> np.ndarray:
        """
        Detect and enhance regions likely to contain text
        Based on connected component analysis
        """
        # Find connected components
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)
        
        # Create mask for text-like components
        mask = np.zeros_like(image)
        
        for i in range(1, num_labels):
            x, y, w, h, area = stats[i]
            
            # Filter by aspect ratio and size (text characteristics)
            aspect_ratio = w / h if h > 0 else 0
            
            # Text typically has aspect ratio between 0.1 and 10
            # and reasonable size
            if 0.1 < aspect_ratio < 10 and area > 20 and area < image.size * 0.5:
                mask[labels == i] = 255
        
        return mask
    
    def apply_unsharp_mask(self, image: np.ndarray, sigma: float = 1.0, 
                          strength: float = 1.5) -> np.ndarray:
        """
        Unsharp masking to enhance edges and fine details
        """
        blurred = cv2.GaussianBlur(image, (0, 0), sigma)
        sharpened = cv2.addWeighted(image, 1.0 + strength, blurred, -strength, 0)
        return sharpened


# Convenience functions for backward compatibility
def preprocess_engraved_text(image: np.ndarray) -> np.ndarray:
    """Legacy function - uses laser-etched preprocessing"""
    preprocessor = ICMarkingPreprocessor()
    return preprocessor.preprocess_laser_etched(image)


def preprocess_for_trocr(image: np.ndarray) -> np.ndarray:
    """TrOCR-optimized preprocessing"""
    preprocessor = ICMarkingPreprocessor()
    return preprocessor.preprocess_printed_text(image)


def preprocess_for_easyocr(image: np.ndarray) -> np.ndarray:
    """EasyOCR-optimized preprocessing"""
    preprocessor = ICMarkingPreprocessor()
    return preprocessor.preprocess_laser_etched(image)


def preprocess_for_doctr(image: np.ndarray) -> np.ndarray:
    """docTR-optimized preprocessing"""
    preprocessor = ICMarkingPreprocessor()
    return preprocessor.preprocess_printed_text(image)


def create_multiple_variants(image: np.ndarray) -> List[Tuple[str, np.ndarray]]:
    """Create multiple preprocessing variants"""
    preprocessor = ICMarkingPreprocessor()
    return preprocessor.create_preprocessing_variants(image)
